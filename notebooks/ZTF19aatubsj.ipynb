{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table\n",
    "from astropy import units as u\n",
    "import seaborn as sns\n",
    "from thesis import output_folder, big_fontsize, base_width, base_height, dpi\n",
    "from IPython.display import display, Markdown\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{romanbar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = 1. + 0.266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swift_ref_time = Time(59007.690095, format='mjd')\n",
    "swift_ref_time = Time(51910, format='mjd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from avro\n",
    "\n",
    "refmag = {\n",
    "    \"g\": 20.031999588012695,\n",
    "    \"r\": 19.325000762939453,\n",
    "    \"i\": 18.906999588012695\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/tywin.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8bf302e60b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/tywin.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis_code/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis_code/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis_code/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis_code/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis_code/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis_code/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis_code/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/tywin.csv'"
     ]
    }
   ],
   "source": [
    "fp = pd.read_csv(\"data/tywin.csv\", sep=\",\", index_col=0)\n",
    "print(fp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "photometry = pd.read_csv(\"data/tywin.csv\", sep=\",\")\n",
    "mask = np.array([x in [\"r\", \"g\", \"i\"] for x in photometry[\"filter\"]])\n",
    "photometry = photometry[mask]\n",
    "print(photometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "swift_data = pd.DataFrame()\n",
    "\n",
    "filtermap = {\n",
    "    \"UUU\": \"U\",\n",
    "    \"UM2\": \"UVM2\",\n",
    "    \"UW2\": \"UVW2\",\n",
    "    \"UW1\": \"UVW1\"\n",
    "}\n",
    "\n",
    "extra_dir = \"data/ZTF19aatubsj_mag/\"\n",
    "for name in sorted(os.listdir(extra_dir)):\n",
    "    fid = name.split(\".\")[0]\n",
    "    if fid in filtermap.keys():\n",
    "        path = os.path.join(extra_dir, name)\n",
    "        new = pd.read_table(path, sep=\"\\s+\", names=[\"date_met\", \"lim_mag\", \"mag\", \"mag_err\"])\n",
    "        \n",
    "        \n",
    "        \n",
    "        mjd = [(swift_ref_time  + (x * u.s)).mjd for x in new[\"date_met\"]]\n",
    "        \n",
    "#         print(new[\"date_met\"][0]/(60*60*24*365))\n",
    "        \n",
    "        new = new.assign(filter=filtermap[fid], date_mjd=mjd)\n",
    "        swift_data = pd.concat([new, swift_data])\n",
    "\n",
    "print(swift_data)\n",
    "# print(os.listdir(extra_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_mask = np.logical_and(\n",
    "    np.logical_and(\n",
    "        photometry[\"magpsf\"] != 99.,\n",
    "#         photometry[\"instrument\"] == \"P48+ZTF\"\n",
    "        True\n",
    "    ),\n",
    "    photometry[\"isdiffpos\"] == True\n",
    ")\n",
    "\n",
    "obs = photometry[det_mask]\n",
    "lim = photometry[~det_mask]\n",
    "\n",
    "plt.figure(figsize=(base_width, base_height), dpi=dpi)\n",
    "ax = plt.subplot(111)\n",
    "ax1b = ax.twinx()\n",
    "\n",
    "cmap = {\n",
    "    \"g\": \"g\",\n",
    "    \"r\": \"r\",\n",
    "    \"i\": \"orange\",\n",
    "    \"UVW2\": \"violet\",\n",
    "    \"UVM2\": \"purple\",\n",
    "    \"UVW1\": \"darkblue\",\n",
    "    \"U\": \"lightblue\",\n",
    "#     \"u\": \"lightblue\",\n",
    "#     \"B\": \"blue\",\n",
    "#     \"z\": \"darkorange\",\n",
    "#     \"V\": \"grey\"\n",
    "}\n",
    "\n",
    "# for f in list(set(obs[\"filter\"])):\n",
    "\n",
    "delta = None\n",
    "\n",
    "for f in cmap.keys():\n",
    "    \n",
    "    if f in list(set(obs[\"filter\"])):\n",
    "    \n",
    "        df = obs[obs[\"filter\"] == f]\n",
    "\n",
    "    #     factor = (df[\"isdiffpos\"])*2 - 1.\n",
    "\n",
    "    #     mag = -2.5 * np.log10(10**(-0.4*refmag[f[-1]]) + factor * 10.**(-0.4*df[\"magpsf\"]))\n",
    "\n",
    "    #     mask = factor > 0.\n",
    "\n",
    "        ax.errorbar(df[\"jdobs\"]-2400000.5, df[\"magpsf\"], yerr=df[\"sigmamagpsf\"], color=cmap[f], marker=\"o\", linestyle=\" \", label=f)\n",
    "\n",
    "        delta = np.mean(df[\"magpsf\"] - df[\"absmag\"])\n",
    "        print(delta)\n",
    "\n",
    "        ax1b.errorbar(df[\"jdobs\"]-2400000.5, df[\"absmag\"], color=cmap[f], yerr=df[\"sigmamagpsf\"], marker=\"o\", linestyle=\" \")\n",
    "\n",
    "for f in filtermap.values():\n",
    "    \n",
    "    df = swift_data[swift_data[\"filter\"] == f]\n",
    "    \n",
    "    ax.errorbar(df[\"date_mjd\"], df[\"mag\"], yerr=df[\"mag_err\"], color=cmap[f], marker=\"o\", linestyle=\" \", label=f)\n",
    "    ax1b.errorbar(df[\"date_mjd\"], df[\"mag\"] - delta, yerr=df[\"mag_err\"], color=cmap[f], marker=\"o\", linestyle=\" \")\n",
    "    #     ax.axhline(refmag[f[-1]], color=cmap[f[-1]], linestyle=\"--\")\n",
    "    \n",
    "#     ldf = lim[lim[\"filter\"] == f]    \n",
    "#     limmag = -2.5 * np.log10(10**(-0.4*refmag[f[-1]]) + 10.**(-0.4*ldf[\"limmag\"]))\n",
    "#     ax.errorbar(ldf[\"jdobs\"]-2400000.5, limmag, color=cmap[f[-1]], linestyle=\" \", uplims=True)\n",
    "#     ax1b.errorbar(ldf[\"jdobs\"]-2400000.5, limmag - delta, color=cmap[f[-1]], linestyle=\" \", uplims=True, marker=\"v\")\n",
    "    \n",
    "ax.invert_yaxis()\n",
    "ax1b.invert_yaxis()\n",
    "ax.set_ylabel(r\"Apparent Magnitude\", fontsize=big_fontsize)\n",
    "ax1b.set_ylabel(rf\"Absolute Magnitude (z={redshift-1.:.3f})\", fontsize=big_fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=big_fontsize)\n",
    "ax1b.tick_params(axis='both', which='major', labelsize=big_fontsize)\n",
    "ax.set_xlabel(\"Date (MJD)\", fontsize=big_fontsize)\n",
    "\n",
    "t_neutrino = Time(\"2020-05-30T07:54:29.43\", format='isot', scale='utc')\n",
    "\n",
    "\n",
    "ax.axvline(t_neutrino.mjd, linestyle=\":\", label=\"IC200530A\")\n",
    "\n",
    "ax.legend(fontsize=big_fontsize, ncol=2)\n",
    "\n",
    "filename = \"AT2019fdr_lightcurve.pdf\"\n",
    "\n",
    "output_path = os.path.join(output_folder, f\"ZTF/{filename}\")\n",
    "plt.ylim()\n",
    "\n",
    "plt.savefig(f\"plots/{filename}\")\n",
    "plt.savefig(output_path)\n",
    "\n",
    "\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour = pd.read_table(\"data/run00134139.evt000035473338.HESE.contour_90.txt\", sep=\" \", names=[\"ra\", \"dec\"], comment='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(base_width, base_height), dpi=dpi)\n",
    "plt.plot(np.degrees(contour[\"ra\"]), np.degrees(contour[\"dec\"]))\n",
    "plt.scatter(257.2785777, 26.8557286, color=\"k\", marker=\"*\", s=100)\n",
    "\n",
    "plt.ylabel(\"Declination [deg]\", fontsize=big_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=big_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=big_fontsize)\n",
    "plt.xlabel(\"Right Ascension [deg]\", fontsize=big_fontsize)\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "filename = \"tywin_position.pdf\"\n",
    "\n",
    "output_path = os.path.join(output_folder, f\"ZTF/{filename}\")\n",
    "\n",
    "plt.savefig(f\"plots/{filename}\")\n",
    "plt.savefig(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_disc = Time(\"2019-05-03T00:00:00\", format='isot', scale='utc')\n",
    "\n",
    "spectra_paths = [\n",
    "    \"2019-06-16.16_HET_HET-LRS_TexSNs.dat\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(base_width, base_height), dpi=dpi)\n",
    "ax1 = plt.subplot(111)\n",
    "j = 0\n",
    "\n",
    "# Redo with actual numbers, not Robert-on-train-reads-off-plot\n",
    "\n",
    "cols = [\"C9\", \"C7\", \"k\", \"k\"]\n",
    "# cols = [\":\", \"--\", \"-.\", \"-\"]\n",
    "\n",
    "lines = [\n",
    "    (r\"$\\rm{H\\alpha}$\", 6562.8, 0),\n",
    "    (r\"$\\rm{H\\beta}$\", 4861, 0),\n",
    "    (r\"$\\rm{H\\gamma}$\", 4340, 0),\n",
    "#     (r\"$\\rm{He\\Romanbar{II}}$\", 4686, 1),\n",
    "#     (r\"$\\rm{N\\Romanbar{III}}$\", 4640, 2),\n",
    "#     (r\"$\\rm{N\\Romanbar{III}}$\", 4100, 2),\n",
    "#     (r\"$\\rm{O\\Romanbar{III}}$\", 3760, 3)\n",
    "]\n",
    "\n",
    "for base_path in spectra_paths:\n",
    "    path = os.path.join(\"data\", base_path)\n",
    "    \n",
    "    name = os.path.basename(path).split(\"_\")\n",
    "    vetos = [\"P60\"]\n",
    "    \n",
    "    raw_date = name[0]\n",
    "    date = Time(f\"{raw_date[:10]}T00:00:00.00\", format='isot', scale='utc')\n",
    "    n_days = date.mjd - t_disc.mjd\n",
    "    \n",
    "    if np.sum([x in name for x in vetos]) == 0:\n",
    "        \n",
    "        if \"ascii\" in path:\n",
    "            data = pd.read_table(path, names=[\"wl\", \"flux\", \"flux_err\"], sep=\" \", comment='#')\n",
    "        else:\n",
    "            data = pd.read_csv(path, names=[\"wl\", \"flux\"], sep=\"  \", index_col=None)\n",
    "            print(data)\n",
    "        mask = data[\"flux\"] > 0.\n",
    "        data[~mask] = np.nan\n",
    "        \n",
    "        if np.sum(~mask) == 1.:\n",
    "            index = list(mask).index(0)\n",
    "            lower = data[:index]\n",
    "            upper = data[index:]\n",
    "#             lower[\"flux\"] *= lower[\"wl\"]**2/np.mean(lower[\"wl\"]**2)\n",
    "            lower[\"flux\"] /= np.mean(lower[\"flux\"])\n",
    "            upper[\"flux\"] /= np.mean(upper[\"flux\"])\n",
    "\n",
    "            lower[\"flux\"] *= upper[\"flux\"].iloc[1]/lower[\"flux\"].iloc[-1]\n",
    "        \n",
    "        label = f\"+{n_days:.0f} days ({name[2][:4]})\"\n",
    "        y_pos = 0.5 - float(j)\n",
    "        \n",
    "        plt.plot(data[\"wl\"]/redshift, y_pos + data[\"flux\"]/np.mean(data[\"flux\"]), label=label)\n",
    "        plt.annotate(label, (5000., y_pos + 0.5), color=f\"C{int(j/2)}\", fontsize=big_fontsize)\n",
    "        j += 2.0\n",
    "# plt.yscale(\"log\")\n",
    "# plt.legend(fontsize=big_fontsize)\n",
    "\n",
    "for (label, wl, col) in lines:\n",
    "    plt.axvline(wl, linestyle=\":\", color=cols[col])\n",
    "    \n",
    "    bbox = dict(boxstyle=\"round\", fc=\"white\", ec=cols[col])\n",
    "    \n",
    "    plt.annotate(label, (wl + 40., 3.5 + 0.9*col), fontsize=big_fontsize, bbox=bbox, color=cols[col])\n",
    "    \n",
    "bbox = dict(boxstyle=\"circle\", fc=\"white\", ec=\"k\")\n",
    "\n",
    "# plt.annotate(\"+\", (7150., 16.6), fontsize=big_fontsize, bbox=bbox, color=cols[col])\n",
    "\n",
    "plt.ylabel(r\"$F_{\\lambda}$ + offset\", fontsize=big_fontsize)\n",
    "ax1.set_ylim(top=5.5)\n",
    "ax1b = ax1.twiny()\n",
    "ax1.set_xlim(left=3500, right=8000)\n",
    "rslim = ax1.get_xlim()\n",
    "ax1b.set_xlim((rslim[0] * redshift, rslim[1] * redshift))\n",
    "ax1.set_xlabel(r\"Rest Wavelength ($\\rm \\AA$)\", fontsize=big_fontsize)\n",
    "ax1b.set_xlabel(rf\"Observed Wavelength (z={redshift-1.:.3f})\", fontsize=big_fontsize)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=big_fontsize)\n",
    "ax1b.tick_params(axis='both', which='major', labelsize=big_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "filename = \"tywin_spectra.pdf\"\n",
    "\n",
    "output_path = os.path.join(output_folder, f\"ZTF/{filename}\")\n",
    "\n",
    "plt.savefig(f\"plots/{filename}\")\n",
    "plt.savefig(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_ztf = 1.37 + 21.57 + 4.52 + 4.09 + 20.56 + 6.22 + 20.06 + 2.66 + (0.9 * 25.3)\n",
    "print(f\"Summed ZTF area is {area_ztf:.2f} sq.deg.\")\n",
    "ztf_n_tde = 5.\n",
    "\n",
    "# ZTF can observe between -30 deg and +90 deg\n",
    "\n",
    "\n",
    "# frac_ztf = 0.5\n",
    "\n",
    "# Take half?\n",
    "\n",
    "ztf_sky = 28000.\n",
    "\n",
    "n_year_ztf = 2.0\n",
    "name = \"NLSy1\"\n",
    "\n",
    "print(f\"ZTF can access {ztf_sky:.2f} sq. deg of sky over a year.\")\n",
    "\n",
    "ztf_tde_disc_rate = ztf_n_tde / n_year_ztf / ztf_sky\n",
    "\n",
    "print(f\"ZTF found {ztf_n_tde} {name} in {n_year_ztf} years in 33000 sq. deg, \"\n",
    "      f\"giving {ztf_tde_disc_rate:.2g} new {name}s per sq. deg per year or \"\n",
    "      f\"giving {(ztf_tde_disc_rate/365.25):.2g} new {name}s per sq. deg per year\")\n",
    "\n",
    "n_year = 1.0\n",
    "\n",
    "ztf_tde_rate = ztf_tde_disc_rate * n_year\n",
    "\n",
    "print(f\"We assume that each {name} is visible for an average of {n_year} years, giving a detection rate of {ztf_tde_rate:.2g} observed {name}s per sq deg at any one time.\")\n",
    "\n",
    "ztf_expectation = ztf_tde_rate * area_ztf\n",
    "print(f\"Given a {name} rate of {ztf_tde_rate:.3g} per sq. deg in ZTF, we have a final rate of {ztf_tde_rate:.2g}\")\n",
    "print(f\"We thus expect {ztf_expectation:.3g} across all observed neutrinos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_code",
   "language": "python",
   "name": "thesis_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
